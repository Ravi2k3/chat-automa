I have 2 codes. One is my chat system code and another is a book summary code. I need you to smartly add the book summary in my chat system.
Add two buttons after starting animation. If user clicks on "General", they are redirected to the normal chat (Interview BOT). If user clicks on Book Summary, they are redirected to the book summary page.
The book summary page should match the UI of the chat_system (we will fine tune it later.)
The book summary bot must be smart and not take a lot of gpt3 tokens. Don't send the chat_history back to the same prompt (to save tokens as history not needed fpor book). It must have a chat_history for the same quiz functionality as the normal chat system. 
I have styles.css, home.hmtl, login.html, quiz.html, score.html. Tell me if you need any of these.
Here are my codes:
1. chat_system.py 
"""# Code for the chat system
# Copyright (c) 2023, Automa
# Unauthorized copying of this file, via any medium is strictly prohibited.
# Proprietary and confidential.

from flask import Flask, request, session, redirect, url_for, flash, render_template, get_flashed_messages, send_from_directory
from email_validator import validate_email, EmailNotValidError
import openai, json
from flask_sqlalchemy import SQLAlchemy
import os
from dotenv import load_dotenv
from datetime import datetime as dt, timedelta
from bs4 import BeautifulSoup
from openai.error import OpenAIError
from werkzeug.exceptions import HTTPException


app = Flask(__name__)
load_dotenv()

app = Flask(__name__)
app.config['SECRET_KEY'] = os.getenv('SECRET_KEY')
openai.api_key = os.getenv('OPENAI_API_KEY')

app.config['SQLALCHEMY_DATABASE_URI'] = os.getenv('DATABASE_URL')

session_counts = {}
last_updated_dates = {}
db = SQLAlchemy(app)

class UserSession(db.Model):
    email = db.Column(db.String(120), primary_key=True)
    session_count = db.Column(db.Integer, default=0)
    message_count = db.Column(db.Integer, default=0)
    quiz_count = db.Column(db.Integer, default=0)  # New field for number of quizzes
    normalized_score = db.Column(db.Float, default=0.0)  # New field for normalized score
    last_updated_date = db.Column(db.Date, default=dt.today)

with app.app_context():
    db.create_all()

@app.route('/favicon.ico')
def favicon():
    return send_from_directory(app.root_path, './favicon.ico', mimetype='image/vnd.microsoft.icon')

@app.errorhandler(404)
def not_found_error(error):
    flash('Page not found', 'error')
    return render_template('404.html'), 404


@app.errorhandler(500)
def internal_error(error):
    flash('Internal server error. Please try again later.', 'error')
    return render_template('500.html'), 500

@app.errorhandler(Exception)
def handle_exception(e):
    # pass through HTTP errors
    if isinstance(e, HTTPException):
        return e

    # now you're handling non-HTTP exceptions only
    flash('An error occurred. Please try again later.', 'error')
    return render_template('500.html'), 500

def is_email_allowed(email):
    email = email.lower()
    allowed_emails = [e.lower() for e in json.load(open("./allowed_emails.json", "r"))]
    return email in allowed_emails


def is_email_valid(email):
    try:
        v = validate_email(email)
        return True
    except EmailNotValidError as e:
        print(str(e))
        return False

def format_message(message):
    lines = message.split('\n')  # split the message into lines
    formatted_lines = [f'<p>{line}</p>' for line in lines if line.strip() != '']  # wrap each line in <p> tags
    return ''.join(formatted_lines)

def ask_gpt_doubt_clearing(question):
    conversation = session.get('conversation', [])
    conversation.append({"role": "user", "content": question})
    try:
        response = openai.ChatCompletion.create(
          model="gpt-3.5-turbo",
          messages=conversation
        )
    except OpenAIError as e:
        if 'rate limit' in str(e):
            flash('Rate limit exceeded. Please try again after a few seconds.', 'error')
            return redirect(url_for('home'))
        else:
            flash('An error occurred. Please try again later.', 'error')
            return redirect(url_for('home'))
        
    answer = format_message(response['choices'][0]['message']['content'])  # format the answer
    # Parse the HTML and extract the text
    soup = BeautifulSoup(answer, 'html.parser')
    text = soup.get_text()
    # Write the question and answer to the user's chat history file
    with open(session['chat_history_file_path'], "a+") as f:
        json.dump({"Question": question,
                   "Answer": text}, f)
        f.write(",\n")  # Write a newline character after each JSON object
        f.seek(0)  # Go back to the beginning of the file

    conversation.append({"role": "assistant", "content": answer})
    session['conversation'] = conversation
    return answer

@app.route('/download/<filename>')
def download(filename):
    return send_from_directory(session['email'], filename, as_attachment=True)


@app.route('/login', methods=['GET', 'POST'])
def login():
    if request.method == 'POST':
        email = request.form['email']
        email = email.strip().lower()
        if is_email_valid(email) and is_email_allowed(email):
            user_session = UserSession.query.get(email)
            current_date = dt.utcnow().date()
            if user_session is not None:
                # Check if the current date is different from the stored date
                if user_session.last_updated_date != current_date:
                    # If the date has changed, reset the session count
                    user_session.session_count = 1
                elif user_session.session_count >= 15:
                    flash('You have reached the maximum number of sessions for today. Please try again tomorrow.', 'error')
                    return redirect(url_for('login'))
                else:
                    user_session.session_count += 1

                # Always update the last_updated_date to the current date
                user_session.last_updated_date = current_date
                user_session.message_count = 0
                
            else:
                user_session = UserSession(email=email, session_count=1, last_updated_date=current_date)
                db.session.add(user_session)
            db.session.commit()
            session['email'] = email
            # Create a new directory for this user
            users_directory = os.path.join(os.getcwd(), "Users")
            os.makedirs(users_directory, exist_ok=True)
            directory = os.path.join(users_directory, email)
            os.makedirs(directory, exist_ok=True)
            
            os.makedirs(directory, exist_ok=True)
            # Store the paths to the chat history and correct answers files for this user
            session['chat_history_file_path'] = os.path.join(directory, "chat_history.json")
            session['quiz_file_path'] = os.path.join(directory, "quiz.txt")
            # Check if the chat history file exists, if not, create it
            session.pop('quizzes', None)  # Clear the quizzes
            session['just_logged_in'] = True  # Set a session variable to indicate that the user has just logged in
            
            # Set the role content to be a Google interviewer.
            role_content = f"""You are a well known interviewer at Google.
            You are having a conversation with a person who is asking you doubts about the interviews....
            """

            session['conversation'] = [{"role": "system", "content": role_content}]
            return redirect(url_for('home'))
        else:
            flash('Invalid email address. Please enter a valid NMIT email address.')
    return render_template('login.html')

@app.route('/unset_just_logged_in', methods=['POST'])
def unset_just_logged_in():
    session.pop('just_logged_in', None)
    return '', 204

@app.route('/logout')
def logout():
    session.pop('email', None)
    session.pop('conversation', None)
    session.pop('quizzes', None)  # Clear the quizzes
    # Don't reset the session count and last updated date
    return redirect(url_for('login'))


@app.route('/', methods=['GET', 'POST'])
def home():
    if 'email' not in session:
        return redirect(url_for('login'))
    
    if request.method == 'POST':
        user_session = UserSession.query.get(session['email'])
        if user_session.message_count is not None and  user_session.message_count >= 5:
            flash('You have reached the maximum number of questions for this session. Please take the quiz to ask more questions.', 'error')
            return redirect(url_for('home'))
        else:
            user_session.message_count += 1
            db.session.commit()
        question = request.form['question']
        answer = ask_gpt_doubt_clearing(question)
        messages = get_flashed_messages()
        return render_template('home.html', answer=answer, messages=messages)
    else:
        return render_template('home.html')

@app.route('/quiz', methods=['GET', 'POST'])
def quiz():
    if 'email' not in session or 'conversation' not in session:
        return redirect(url_for('login'))
    
    user_messages = [message for message in session['conversation'] if message['role'] == 'user']
    if len(user_messages) == 0:
        flash("You must ask a question before taking a quiz.", "error")
        return redirect(url_for('home'))
    
    if 'quizzes' not in session or len(session['quizzes']) == 0:
        history = session['conversation']
        prompt = f"""
        Your task is to generate a MCQ quizes based on a conversation. 
        Generate as many questions as necessary and do not go out of the context of the conversation.
        Number the questions accordingly.
        Each question must have only 1 right answer and each answer must not exceed one line.
        Also provide the correct answer to the quiz exaclty matching the option. Number the Solution as well 
        Strictly follow the format given below.

        Conversation: '''{history}'''

        Use the following format:
        Question 1:
        ```
        question here
        ```
        A. answer 1.
        ```
        B. answer 2.
        ```
        C. answer 3.
        ```
        D. answer 4
        ```
        Actual solution 1:
        ```
        correct answer here
        """
        messages = history + [{"role": "user", "content": prompt}]
        response = openai.ChatCompletion.create(
        model="gpt-3.5-turbo",
        messages=messages
        )
        content = response['choices'][0]['message']['content']
        
        # Split the content into lines
        lines = content.split("\n")

        # Initialize an empty list to hold the quizzes
        quizzes = []

        # Initialize an empty dictionary to hold the current quiz
        quiz = {}
        # Iterate over the lines
        
        stripped_lines = [line.strip() for line in lines]
        
        for i, line in enumerate(stripped_lines):
            line = line.strip()
            # If the line starts with "Question:", extract the question
            if line.startswith("Question") or "Question" in line:
                # The question is on the second next line, enclosed in triple backticks
                question_line = stripped_lines[i + 2]
                quiz["question"] = question_line.strip("`")
                
            # If the line starts with a letter and a period, extract the option
            elif line.startswith(("A.", "B.", "C.", "D.")):
                option = line[0]
                answer = line.replace(f"{option}.", "").strip(" `")
                quiz[option] = answer
                # Add the option to the list of options
                if option not in quiz.get("options", []):  # Check if the option is already in the list
                    quiz.setdefault("options", []).append(option)
                        
            # If the line starts with "Actual solution:", extract the correct answer
            elif line.startswith("Actual solution"):
                # The correct answer is on the next line, enclosed in triple backticks
                correct_answer_line = stripped_lines[i + 2]
                correct_answer_option = correct_answer_line.strip("`")
                quiz["correct_answer"] = correct_answer_option
                # Add the completed quiz to the list of quizzes
                quizzes.append(quiz)
                # Reset the quiz dictionary for the next quiz
                quiz = {"options": []}

        # Store the quizzes in the session
        session['quizzes'] = quizzes

        # Initialize the quiz index and the score
        session['quiz_index'] = 0
        session['score'] = 0

    # If this is a GET request or the user has just answered a question
    if request.method == 'GET' or 'answer' in request.form:
        # If the user has just answered a question, check if the answer is correct
        if 'answer' in request.form:
            correct_answer = session['quizzes'][session['quiz_index']]['correct_answer']
            if request.form['answer'] in correct_answer:
                session['score'] += 1
                flash('Correct!', 'success')
            else:
                flash('Incorrect.', 'error')

            # Increment the quiz index
            session['quiz_index'] += 1

            # If there are no more quizzes, redirect the user to the score page
            if session['quiz_index'] >= len(session['quizzes']):
                return redirect(url_for('score'))

    if session['quiz_index'] < len(session['quizzes']):
                quiz = session['quizzes'][session['quiz_index']]
    else:
        flash('Sorry, there are no more quizzes.', "error")
        return redirect(url_for('home'))

    return render_template('quiz.html', quiz=quiz, message =get_flashed_messages())


@app.route('/score')
def score():
    if 'email' not in session or 'score' not in session:
        return redirect(url_for('login'))

    return render_template('score.html', score=session['score'], quizzes=session['quizzes'])  # Send the quizzes to the frontend

@app.route('/download_chat_history')
def download_chat_history():
    return send_from_directory('Users/'+session['email'], 'chat_history.json', as_attachment=True)

@app.route('/download_quizzes')
def download_correct_answers():
    return send_from_directory('Users/'+session['email'], 'quiz.txt', as_attachment=True)

@app.route('/quiz_answer', methods=['POST'])
def quiz_answer():
    if 'email' not in session:
        return redirect(url_for('login'))
    
    if 'answer' in request.form:
        user_answer = request.form['answer']
        quiz = session['quizzes'][session['quiz_index']]
        correct_answer = quiz['correct_answer']
        user_session = UserSession.query.get(session['email'])
        user_session.quiz_count += 1  # Increment the quiz count
                    
        with open(session['quiz_file_path'], "a+") as f:
            f.write(f"Question: {quiz['question']}\n")
            f.write(f"A: {quiz['A']}\n")
            f.write(f"B: {quiz['B']}\n")
            f.write(f"C: {quiz['C']}\n")
            f.write(f"D: {quiz['D']}\n")
            f.write(f"Correct Answer: {quiz['correct_answer']}\n\n")


        if user_answer in correct_answer:
            session['score'] += 1
            flash('Correct!', 'success')
            user_session.normalized_score += 10 / len(session['quizzes'])  # Update the normalized score
        else:
            flash('Incorrect.', 'error')
        db.session.commit()  # Don't forget to commit the changes

    # Increment the quiz index
    session['quiz_index'] += 1

    # If there are no more quizzes, redirect the user to the score page
    if session['quiz_index'] >= len(session['quizzes']):
        return redirect(url_for('score'))

    return redirect(url_for('quiz'))

app.static_folder = 'static'
if __name__ == '__main__':
    app.run(debug=True, host="127.0.0.1", port=5000)"""

2. basic book system code from hugging face that needs to be heavily modified UI wise and integrated into my code
"""import urllib.request
import fitz
import re
import numpy as np
import tensorflow_hub as hub
import openai
import gradio as gr
import os
from sklearn.neighbors import NearestNeighbors


def download_pdf(url, output_path):
    urllib.request.urlretrieve(url, output_path)


def preprocess(text):
    text = text.replace('\n', ' ')
    text = re.sub('\s+', ' ', text)
    return text


def pdf_to_text(path, start_page=1, end_page=None):
    doc = fitz.open(path)
    total_pages = doc.page_count

    if end_page is None:
        end_page = total_pages

    text_list = []

    for i in range(start_page-1, end_page):
        text = doc.load_page(i).get_text("text")
        text = preprocess(text)
        text_list.append(text)

    doc.close()
    return text_list


def text_to_chunks(texts, word_length=150, start_page=1):
    text_toks = [t.split(' ') for t in texts]
    page_nums = []
    chunks = []
    
    for idx, words in enumerate(text_toks):
        for i in range(0, len(words), word_length):
            chunk = words[i:i+word_length]
            if (i+word_length) > len(words) and (len(chunk) < word_length) and (
                len(text_toks) != (idx+1)):
                text_toks[idx+1] = chunk + text_toks[idx+1]
                continue
            chunk = ' '.join(chunk).strip()
            chunk = f'[{idx+start_page}]' + ' ' + '"' + chunk + '"'
            chunks.append(chunk)
    return chunks


class SemanticSearch:
    
    def __init__(self):
        self.use = hub.load('https://tfhub.dev/google/universal-sentence-encoder/4')
        self.fitted = False
    
    
    def fit(self, data, batch=1000, n_neighbors=5):
        self.data = data
        self.embeddings = self.get_text_embedding(data, batch=batch)
        n_neighbors = min(n_neighbors, len(self.embeddings))
        self.nn = NearestNeighbors(n_neighbors=n_neighbors)
        self.nn.fit(self.embeddings)
        self.fitted = True
    
    
    def __call__(self, text, return_data=True):
        inp_emb = self.use([text])
        neighbors = self.nn.kneighbors(inp_emb, return_distance=False)[0]
        
        if return_data:
            return [self.data[i] for i in neighbors]
        else:
            return neighbors
    
    
    def get_text_embedding(self, texts, batch=1000):
        embeddings = []
        for i in range(0, len(texts), batch):
            text_batch = texts[i:(i+batch)]
            emb_batch = self.use(text_batch)
            embeddings.append(emb_batch)
        embeddings = np.vstack(embeddings)
        return embeddings


recommender = SemanticSearch()

def load_recommender(path, start_page=1):
    global recommender
    texts = pdf_to_text(path, start_page=start_page)
    chunks = text_to_chunks(texts, start_page=start_page)
    recommender.fit(chunks)
    return 'Corpus Loaded.'


def text_generation(question):
    conversation = session.get('conversation', [])
    conversation.append({"role": "user", "content": question})
    try:
        response = openai.ChatCompletion.create(
          model="gpt-3.5-turbo",
          messages=conversation
        )
    except OpenAIError as e:
        if 'rate limit' in str(e):
            flash('Rate limit exceeded. Please try again after a few seconds.', 'error')
            return redirect(url_for('home'))
        else:
            flash('An error occurred. Please try again later.', 'error')
            return redirect(url_for('home'))
        
    answer = format_message(response['choices'][0]['message']['content'])  # format the answer
    # Parse the HTML and extract the text
    soup = BeautifulSoup(answer, 'html.parser')
    text = soup.get_text()
    # Write the question and answer to the user's chat history file
    with open(session['chat_history_file_path'], "a+") as f:
        json.dump({"Question": question,
                   "Answer": text}, f)
        f.write(",\n")  # Write a newline character after each JSON object
        f.seek(0)  # Go back to the beginning of the file

    conversation.append({"role": "assistant", "content": answer})
    session['conversation'] = conversation
    return answer


def generate_answer(question):
    topn_chunks = recommender(question)
    prompt = ""
    prompt += 'search results:\n\n'
    for c in topn_chunks:
        prompt += c + '\n\n'
        
    prompt += "Instructions: Compose a comprehensive reply to the query using the search results given. "\
              "Cite each reference using [number] notation (every result has this number at the beginning). "\
              "Citation should be done at the end of each sentence. If the search results mention multiple subjects "\
              "with the same name, create separate answers for each. Only include information found in the results and "\
              "don't add any additional information. Make sure the answer is correct and don't output false content. "\
              "If the text does not relate to the query, simply state 'Found Nothing'. Ignore outlier "\
              "search results which has nothing to do with the question. Only answer what is asked. The "\
              "answer should be short and concise.\n\nQuery: {question}\nAnswer: "
    
    prompt += f"Query: {question}\nAnswer:"
    answer = generate_text(prompt)
    return answer


def question_answer(url, file, question, api_key):
    openai.api_key = api_key

    if url.strip() == '' and file == None:
        return '[ERROR]: Both URL and PDF is empty. Provide atleast one.'
    
    if url.strip() != '' and file != None:
        return '[ERROR]: Both URL and PDF is provided. Please provide only one (eiter URL or PDF).'

    if url.strip() != '':
        glob_url = url
        download_pdf(glob_url, 'corpus.pdf')
        load_recommender('corpus.pdf')

    else:
        old_file_name = file.name
        file_name = file.name
        file_name = file_name[:-12] + file_name[-4:]
        os.rename(old_file_name, file_name)
        load_recommender(file_name)

    if question.strip() == '':
        return '[ERROR]: Question field is empty'

    return generate_answer(question)


title = 'BookGPT'
description = "BookGPT allows you to input an entire book and ask questions about its contents. This app uses GPT-3 to generate answers based on the book's information. BookGPT has ability to add reference to the specific page number from where the information was found. This adds credibility to the answers generated also helps you locate the relevant information in the book."

with gr.Blocks() as demo:

    gr.Markdown(f'<center><h1>{title}</h1></center>')
    gr.Markdown(description)
    gr.Markdown("Thank you for all the support this space has received! Unfortunately, my OpenAI $18 grant has been exhausted, so you'll need to enter your own OpenAI API Key to use the app. Sorry for inconvenience :-(.")

    with gr.Row():
        
        with gr.Group():
            url = gr.Textbox(label='URL')
            gr.Markdown("<center><h6>or<h6></center>")
            file = gr.File(label='PDF', file_types=['.pdf'])
            question = gr.Textbox(label='question')
            api_key = gr.Textbox(label='OpenAI API Key')
            btn = gr.Button(value='Submit')
            btn.style(full_width=True)

        with gr.Group():
            answer = gr.Textbox(label='answer')

        btn.click(question_answer, inputs=[url, file, question, api_key], outputs=[answer])

demo.launch()"""